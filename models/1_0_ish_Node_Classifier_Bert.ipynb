{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mistryishan25/Comprehensive-Project-SEM8/blob/master/models/1_0_ish_Node_Classifier_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resource dump:\n",
        "1. Which Free GPUs - [Article](https://towardsdatascience.com/free-gpus-for-training-your-deep-learning-models-c1ce47863350)\n",
        "2. Interpret the working of BERT - [Article](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1)\n",
        "3. Baseline : Naive Bayes + TF-IDF - [Article](https://skimai.com/fine-tuning-bert-for-sentiment-analysis/) "
      ],
      "metadata": {
        "id": "UhQukPckOCZl"
      },
      "id": "UhQukPckOCZl"
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SToxq-cXOCbF"
      },
      "id": "SToxq-cXOCbF"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "nwLlAzX_N_Qd"
      },
      "id": "nwLlAzX_N_Qd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install convokit"
      ],
      "metadata": {
        "id": "0aERSxXWn1wJ"
      },
      "id": "0aERSxXWn1wJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "B07iQ3haoMbw"
      },
      "id": "B07iQ3haoMbw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "SKGLku3-9SEW"
      },
      "id": "SKGLku3-9SEW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eefd4ed0",
      "metadata": {
        "id": "eefd4ed0"
      },
      "source": [
        "### Imports and citations \n",
        "\n",
        "Characterizing Online Discussion Using Coarse Discourse Sequences,\n",
        "Amy Zhang,Bryan Culbertson,Praveen Paritosh\n",
        "\n",
        "\n",
        "Bibtex\n",
        "@inproceedings{46055,\n",
        "title\t= {Characterizing Online Discussion Using Coarse Discourse Sequences},\n",
        "author\t= {Amy Zhang and Bryan Culbertson and Praveen Paritosh},\n",
        "year\t= {2017}\n",
        "}\n",
        "\n",
        "Reference : [Link](https://colab.research.google.com/github/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/Introduction_to_ConvoKit.ipynb#scrollTo=kHB78-JtViKt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data related imports\n",
        "import convokit\n",
        "from convokit import Corpus, download\n",
        "import re\n",
        "import contractions\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# utilities\n",
        "from google.colab import output"
      ],
      "metadata": {
        "id": "rlYALHWLZ87G"
      },
      "id": "rlYALHWLZ87G",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b17e521b",
      "metadata": {
        "id": "b17e521b"
      },
      "outputs": [],
      "source": [
        "BASE_CORPUS = Corpus(download(\"reddit-coarse-discourse-corpus\"));\n",
        "#corpus.print_summary_stats();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca0c211",
      "metadata": {
        "id": "9ca0c211"
      },
      "source": [
        "### What each utterance contains?\n",
        "1. comment_depth: depth of the comment, 0 if the utterance is the top-level post itself.\n",
        "2. majority type: discourse action type by one of the following: question, answer, announcement, agreement, appreciation, disagreement, elaboration, humor\n",
        "3. annotation_types (list of annotation types by three annotators)\n",
        "4. majority_link : link in relation to previous post, none if no relation with previous comment\n",
        "5. annotation_links (list of annotation links by three annotators)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d50f82cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d50f82cb",
        "outputId": "bea0418f-8e2e-442d-aabc-c1b28ebc5d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go on...\n",
            "----------------------------------------\n",
            "In my old house, my local sorting office was a 10 minute walk away, in a residential area, with good bus links.\n",
            "\n",
            "Having moved a mile down the road, my sorting office has changed. \n",
            "\n",
            "My new sorting office is in a business estate on the other side of the City Centre, is atleast 2 bus hops away, through the Centre's Traffic laden one-way system and is still a 10 minute walk across a deadly motorway sliproad, from the nearest bus stop. Conversely, my old one is still only a single 10 minute bus journey away, or a 40 minute walk.\n",
            "\n",
            "Damn you Royal Mail.\n",
            "----------------------------------------\n",
            "Just buy an x-arcade stick.\n",
            "----------------------------------------\n",
            "You are being dismissive again with the following, \n",
            "\n",
            ">It's such a conformist attitude to just expend all your time and effort into a genre that already exists and still consider yourself and individual\n",
            "\n",
            "  This is exactly what I was talking about before, you are essentially telling anyone who ever found a genre that they really liked, people who invested significant amounts of effort into mastering a specific (existing) genre or set of (existing) genre's that they are un-creative, that they don't find ways to express themselves creatively just because they happen to play genre's that already exist.\n",
            " \n",
            " That is absurd, ignorant and dismissive.\n",
            " \n",
            " This is not just about blues, it is about every genre, are you going to tell Steve Vai that he is not unique because he is playing in the heavy rock genre? Are you going to tell Joe Pass that he can't express himself because he happens to play Jazz and since that already exists, all the creative work was already done for him? \n",
            "\n",
            "  I am not being defensive about blues, I am telling you that the end-game of music is not always to be a special snow-flake who is 100% original, having a preferred genre (or genres) does not mean that you are not creative or capable of creating new things in those genres.\n",
            "\n",
            "  Finally, how about you provide some examples of your new and amazing genre's that you just invented since you have made it clear that playing in a existing genre is \"conformist\".   \n",
            "----------------------------------------\n",
            "Oh for sure. One of the schools im looking at has a program for animal science, which has similar if not almost the same coursework for biological science. If anything changes i could always go into the other, and enter the vet school they offer. Either way i know i have to get those math and science courses done since almost all the degrees require those specific classes. \n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "utt_5 = []\n",
        "for i in range(5):\n",
        "    utt = BASE_CORPUS.random_utterance()\n",
        "    utt_5.append(utt)\n",
        "    print(utt.text)\n",
        "    print(\"-\"*40)\n",
        "    # print(utt.meta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78050e6c",
      "metadata": {
        "id": "78050e6c"
      },
      "source": [
        "### Explore the conversations\n",
        "\n",
        "1. [ ] How many emojis do we actually have? Are they used instead of words?\n",
        "2. [ ] Explore the distribution of the labels. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82412c78",
      "metadata": {
        "id": "82412c78"
      },
      "source": [
        "- We would be needing only the text and the meta.\n",
        "- Vector attribute stays we might add the vector data for each utterance for other cases- [Link](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/vectors/vector_demo.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "35839e27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "35839e27",
        "outputId": "d210de54-59e8-48da-e18d-702cd5980219"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           timestamp                                               text  \\\n",
              "id                                                                        \n",
              "t3_1bx6qw       None  4/7/13  \\n\\n7/27/12  \\n\\nhttp://www.imdb.com/t...   \n",
              "t1_c9b2nyd      None  I've wanted to watch this for a long time. I w...   \n",
              "t1_c9b30i1      None  You strike me as the type who would appreciate...   \n",
              "t1_c9b6sj0      None  Yeah, I've always heard that Altman was famous...   \n",
              "t3_omv7p        None  Alright guys, little background about myself. ...   \n",
              "\n",
              "              speaker    reply_to conversation_id meta.post_depth  \\\n",
              "id                                                                  \n",
              "t3_1bx6qw      DTX120        None       t3_1bx6qw               0   \n",
              "t1_c9b2nyd  mcgrewf10   t3_1bx6qw       t3_1bx6qw               1   \n",
              "t1_c9b30i1     DTX120  t1_c9b2nyd       t3_1bx6qw               2   \n",
              "t1_c9b6sj0  mcgrewf10  t1_c9b30i1       t3_1bx6qw               3   \n",
              "t3_omv7p     Keatonus        None        t3_omv7p               0   \n",
              "\n",
              "           meta.majority_type meta.majority_link  \\\n",
              "id                                                 \n",
              "t3_1bx6qw        announcement               none   \n",
              "t1_c9b2nyd        elaboration          t3_1bx6qw   \n",
              "t1_c9b30i1        elaboration         t1_c9b2nyd   \n",
              "t1_c9b6sj0        elaboration         t1_c9b30i1   \n",
              "t3_omv7p         announcement               none   \n",
              "\n",
              "                                 meta.annotation-types  \\\n",
              "id                                                       \n",
              "t3_1bx6qw   [announcement, announcement, announcement]   \n",
              "t1_c9b2nyd       [agreement, elaboration, elaboration]   \n",
              "t1_c9b30i1     [elaboration, elaboration, elaboration]   \n",
              "t1_c9b6sj0       [agreement, elaboration, elaboration]   \n",
              "t3_omv7p    [announcement, announcement, announcement]   \n",
              "\n",
              "                           meta.annotation-links meta.ups vectors  \n",
              "id                                                                 \n",
              "t3_1bx6qw                     [none, none, none]        3      []  \n",
              "t1_c9b2nyd     [t3_1bx6qw, t3_1bx6qw, t3_1bx6qw]        2      []  \n",
              "t1_c9b30i1  [t1_c9b2nyd, t1_c9b2nyd, t1_c9b2nyd]        1      []  \n",
              "t1_c9b6sj0  [t1_c9b30i1, t1_c9b30i1, t1_c9b30i1]        1      []  \n",
              "t3_omv7p                      [none, none, none]        6      []  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c09fcf5-91f2-419a-ab0a-0901ba3f3a9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>text</th>\n",
              "      <th>speaker</th>\n",
              "      <th>reply_to</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>meta.post_depth</th>\n",
              "      <th>meta.majority_type</th>\n",
              "      <th>meta.majority_link</th>\n",
              "      <th>meta.annotation-types</th>\n",
              "      <th>meta.annotation-links</th>\n",
              "      <th>meta.ups</th>\n",
              "      <th>vectors</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>t3_1bx6qw</th>\n",
              "      <td>None</td>\n",
              "      <td>4/7/13  \\n\\n7/27/12  \\n\\nhttp://www.imdb.com/t...</td>\n",
              "      <td>DTX120</td>\n",
              "      <td>None</td>\n",
              "      <td>t3_1bx6qw</td>\n",
              "      <td>0</td>\n",
              "      <td>announcement</td>\n",
              "      <td>none</td>\n",
              "      <td>[announcement, announcement, announcement]</td>\n",
              "      <td>[none, none, none]</td>\n",
              "      <td>3</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t1_c9b2nyd</th>\n",
              "      <td>None</td>\n",
              "      <td>I've wanted to watch this for a long time. I w...</td>\n",
              "      <td>mcgrewf10</td>\n",
              "      <td>t3_1bx6qw</td>\n",
              "      <td>t3_1bx6qw</td>\n",
              "      <td>1</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>t3_1bx6qw</td>\n",
              "      <td>[agreement, elaboration, elaboration]</td>\n",
              "      <td>[t3_1bx6qw, t3_1bx6qw, t3_1bx6qw]</td>\n",
              "      <td>2</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t1_c9b30i1</th>\n",
              "      <td>None</td>\n",
              "      <td>You strike me as the type who would appreciate...</td>\n",
              "      <td>DTX120</td>\n",
              "      <td>t1_c9b2nyd</td>\n",
              "      <td>t3_1bx6qw</td>\n",
              "      <td>2</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>t1_c9b2nyd</td>\n",
              "      <td>[elaboration, elaboration, elaboration]</td>\n",
              "      <td>[t1_c9b2nyd, t1_c9b2nyd, t1_c9b2nyd]</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t1_c9b6sj0</th>\n",
              "      <td>None</td>\n",
              "      <td>Yeah, I've always heard that Altman was famous...</td>\n",
              "      <td>mcgrewf10</td>\n",
              "      <td>t1_c9b30i1</td>\n",
              "      <td>t3_1bx6qw</td>\n",
              "      <td>3</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>t1_c9b30i1</td>\n",
              "      <td>[agreement, elaboration, elaboration]</td>\n",
              "      <td>[t1_c9b30i1, t1_c9b30i1, t1_c9b30i1]</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t3_omv7p</th>\n",
              "      <td>None</td>\n",
              "      <td>Alright guys, little background about myself. ...</td>\n",
              "      <td>Keatonus</td>\n",
              "      <td>None</td>\n",
              "      <td>t3_omv7p</td>\n",
              "      <td>0</td>\n",
              "      <td>announcement</td>\n",
              "      <td>none</td>\n",
              "      <td>[announcement, announcement, announcement]</td>\n",
              "      <td>[none, none, none]</td>\n",
              "      <td>6</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c09fcf5-91f2-419a-ab0a-0901ba3f3a9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c09fcf5-91f2-419a-ab0a-0901ba3f3a9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c09fcf5-91f2-419a-ab0a-0901ba3f3a9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df = BASE_CORPUS.get_utterances_dataframe()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1e529a2d",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e529a2d",
        "outputId": "ee3936df-a448-49e7-efb5-835d0a36f1f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115827"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Yes indeed these are the number of utterances in the entire dataset.\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f8d8009a",
      "metadata": {
        "id": "f8d8009a"
      },
      "outputs": [],
      "source": [
        "# Meh not important here anyways\n",
        "df = df.drop([\"timestamp\"], axis=1)\n",
        "\n",
        "# Vectors are also null in a way as they will updated later on with the choice of embedding in the metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "8e4feb89",
      "metadata": {
        "id": "8e4feb89"
      },
      "outputs": [],
      "source": [
        "# Checking for missing values : \n",
        "\n",
        "def missing_values(df):\n",
        "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
        "    # Seperating them into a new df for use later on while testing\n",
        "    missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
        "                                     'percent_missing': percent_missing})\n",
        "    return missing_value_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0ed97ab3",
      "metadata": {
        "id": "0ed97ab3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "525c2207",
      "metadata": {
        "id": "525c2207"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13e0c1e1",
      "metadata": {
        "id": "13e0c1e1"
      },
      "source": [
        "### List of Cleaning to be done\n",
        "1. [x] Clean URls - Convention is [text]\\(URL)\n",
        "2. [x] Do not seperate the quoted text - \"> blah /n/n\n",
        "3. [x] Removing special characters \n",
        "4. [ ] Speling correction? What about the ones that convey info?\n",
        "5. [ ] Deal with Emojis and emoticons - [emot lib](https://medium.com/geekculture/text-preprocessing-how-to-handle-emoji-emoticon-641bbfa6e9e7) \n",
        "6. [x] Contractions need to be taken care of -\n",
        "7. [x] Remove /n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9310624a",
      "metadata": {
        "id": "9310624a"
      },
      "source": [
        "Using Regex to do simple cleaning based on symbols - [Documentation](https://docs.python.org/3/library/re.html#re.sub) and many stack-overflow pieces and articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "871318d5",
      "metadata": {
        "id": "871318d5"
      },
      "outputs": [],
      "source": [
        "def clean(text, newline=True, quote=True, bullet_point=True,dates=True,\n",
        "          link=True, strikethrough=True, spoiler=True, heading=True, emoji=True, emoticon=True, contraction=True):\n",
        "    \n",
        "    # Newlines we dont need - only \n",
        "    if newline:\n",
        "        text = re.sub(r'\\n+', ' ', text)\n",
        "        # Remove the many \" \" that we replaced in the last steo\n",
        "        text = text.strip()\n",
        "        text = re.sub(r'\\s\\s+', ' ', text)\n",
        "\n",
        "    # > are for the qouted texts from the main comment or the reply\n",
        "    if quote:\n",
        "        text = re.sub(r'>', '', text)\n",
        "\n",
        "    # Bullet points/asterisk are used for markdown like - bold/italic - Could create trouble in parsing? idk\n",
        "    if bullet_point:\n",
        "        text = re.sub(r'\\*', '', text)\n",
        "        text = re.sub('&amp;#x200B;', '', text)\n",
        "\n",
        "    # []() Link format then we remove both the tag/placeholder and the link\n",
        "    if link:\n",
        "        text = re.sub(r\"http\\S+\", '', text)\n",
        "        text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
        "\n",
        "    # Strikethrough\n",
        "    if strikethrough:\n",
        "        text = re.sub('~', '', text)\n",
        "\n",
        "    # Spoiler, which is used with < less-than (Preserves the text)\n",
        "    if spoiler:\n",
        "        text = re.sub('&lt;', '', text)\n",
        "        text = re.sub(r'!(.*?)!', r'\\1', text)\n",
        "\n",
        "    # Heading to be removed as there are these markdown style features in reddit too\n",
        "    if heading:\n",
        "        text = re.sub('#', '', text)\n",
        "        \n",
        "    if emoji:\n",
        "    # Implement the emoji scheme here. \n",
        "    # Makes more sense for the node feature but might as well import that function here if ready    \n",
        "        pass\n",
        "    if dates:\n",
        "        text = re.sub(r'(\\d+/\\d+/\\d+)', '', text)\n",
        "    if emoticon:\n",
        "    # Implement the emoticon scheme here. \n",
        "    # Makes more sense for the node feature but might as well import that function here if ready \n",
        "        pass\n",
        "    \n",
        "    #Needs to be the last step in the process\n",
        "    if contractions:\n",
        "        text = contractions.fix(text)\n",
        "    #print(\"Running\")    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc6e165",
      "metadata": {
        "id": "1cc6e165"
      },
      "source": [
        "### Ways of transformation to clean \n",
        "1.  Clean() then TextCleaner -----Meh\n",
        "2. TextCleaner then Clean() ---------Meh \n",
        "3. Clean -------------------------MeH\n",
        "4. TextCleaner ------------------Meh\n",
        "5. Clean : Lambda ---------------Bingo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b66025",
      "metadata": {
        "id": "77b66025"
      },
      "source": [
        "The convo-kit has good interoperability with the sklearn package and hence we would have to exploit the sklearn stuff to do the transformation in a single pass instead of iterating over all the utterances - [CovoKit](https://convokit.cornell.edu/documentation/architecture.html#transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6b83e12a",
      "metadata": {
        "id": "6b83e12a"
      },
      "outputs": [],
      "source": [
        "# # Option 1 - Clean -> TextCleaner\n",
        "# corpus_1 = textCleaner.TextCleaner(text_cleaner= clean, input_field = \"text\").transform(BASE_CORPUS);\n",
        "# corpus_2 = textCleaner.TextCleaner(input_field= \"text\").transform(corpus_1);\n",
        "# df_1 = corpus_2.get_utterances_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1dafd9b8",
      "metadata": {
        "id": "1dafd9b8"
      },
      "outputs": [],
      "source": [
        "# missing_1 = missing_values(df_1)\n",
        "# missing_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6fec23ab",
      "metadata": {
        "id": "6fec23ab"
      },
      "outputs": [],
      "source": [
        "# Option 2 TextCleaner -> Clean\n",
        "# corpus_3 = textCleaner.TextCleaner(input_field= \"text\").transform(BASE_CORPUS)\n",
        "# corpus_4 = textCleaner.TextCleaner(text_cleaner= clean, input_field = \"text\").transform(corpus_3)\n",
        "# df_2 = corpus_4.get_utterances_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f0f875f0",
      "metadata": {
        "id": "f0f875f0"
      },
      "outputs": [],
      "source": [
        "# missing_2 = missing_values(df_2)\n",
        "# missing_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ceab8bed",
      "metadata": {
        "id": "ceab8bed"
      },
      "outputs": [],
      "source": [
        "# Option 3 Clean\n",
        "# corpus_5 = textCleaner.TextCleaner(text_cleaner= clean, input_field = \"text\").transform(BASE_CORPUS)\n",
        "# df_3 = corpus_5.get_utterances_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3fe89803",
      "metadata": {
        "scrolled": true,
        "id": "3fe89803"
      },
      "outputs": [],
      "source": [
        "# missing_3 = missing_values(df_3)\n",
        "# missing_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "59378614",
      "metadata": {
        "collapsed": true,
        "id": "59378614"
      },
      "outputs": [],
      "source": [
        "# # Option 4 TextCleaner\n",
        "# corpus_6 = textCleaner.TextCleaner(input_field= \"text\").transform(BASE_CORPUS)\n",
        "# df_4 = corpus_6.get_utterances_dataframe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "04c61af4",
      "metadata": {
        "id": "04c61af4"
      },
      "outputs": [],
      "source": [
        "# missing_4 = missing_values(df_4)\n",
        "# missing_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ae933e57",
      "metadata": {
        "id": "ae933e57"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5bcaf33e",
      "metadata": {
        "id": "5bcaf33e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f316849f",
      "metadata": {
        "id": "f316849f"
      },
      "outputs": [],
      "source": [
        "# Lucky to find that the first utterance is a problem \n",
        "# BASE_CORPUS Version\n",
        "# [df.head(1)][0][\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "09341e87",
      "metadata": {
        "id": "09341e87"
      },
      "outputs": [],
      "source": [
        "# [df_1.head(1)][0][\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ab3b598b",
      "metadata": {
        "id": "ab3b598b"
      },
      "outputs": [],
      "source": [
        "# [df_2.head(1)][0][\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "63fe689c",
      "metadata": {
        "id": "63fe689c"
      },
      "outputs": [],
      "source": [
        "# clean([df_2.head(1)][0][\"text\"][0])\n",
        "\n",
        "# Returns None\n",
        "# [df_3.head(1)][0][\"text\"][0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "1af65729",
      "metadata": {
        "id": "1af65729"
      },
      "outputs": [],
      "source": [
        "# assert df_4[\"text\"].all() == df_2[\"text\"].all() == df_1[\"text\"].all() \n",
        "# Damn why God Why did I waste time then? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4829f0b0",
      "metadata": {
        "id": "4829f0b0"
      },
      "outputs": [],
      "source": [
        "# Option 5 - Use lambda Function\n",
        "df[\"text_clean\"] = df[\"text\"].apply(lambda row : clean(row))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f3876c64",
      "metadata": {
        "id": "f3876c64"
      },
      "outputs": [],
      "source": [
        "# assert df_4[\"text\"][0] == df[\"text_clean\"][0] \n",
        "# Yes it should not be truee so wohhoo!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6d4f6620",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "6d4f6620",
        "outputId": "68fdf331-65e6-4f60-9e27-f7244510bfc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"4/7/13  \\n\\n7/27/12  \\n\\nhttp://www.imdb.com/title/tt0073440/reference\\n\\nIt was only a few minutes into Robert Altman's homespun epic *Nashville* that I got the feeling I was watching a great movie. By the end it could not be denied. Now I'm sure it helps that I'm a musician, since this created an immediate connection to the subject matter. I spent a portion of the movie with my Telecaster in my lap trying to play along with the characters who all seem to be really playing and singing these songs. However I also am *not* a fan of country western, so that could have easily been a turn off.  \\n\\nTo begin describing the action in the film is daunting. I can't even process a lot of what I saw. This movie is extremely dense, and the first 30 minutes or so are spent just trying to figure out who people are. Their relationships to one another - some of which are purely incidental - slowly become clear as things progress. It's an ensemble cast with no clear lead and lots of overlapping conversations. Some developments all tie together in the end. Some seem to be kind of loose ends. There is throughout, however, a very keen sense about people. These naturalistic performances are believable and so is the world they inhabit. It feels like a film that doesn't exaggerate - rather, it downplays some of the outrageousness which just makes it seem all the more outrageous. Consider for example Shelley Duvall's wig or Jeff Goldblum's entire character.  \\n\\nI feel I should mention this. Jeff Goldblum is in this film. He never speaks, and he is awesome.  \\n\\n*Nashville* is a musical. There is reportedly around an hour of music in its 150+ minute run time. I believe it. Sometimes these songs, most if not all of which are original, seem to speak pointedly to or about a character. Sometimes it's all about the shifts and glances in the audience. There are many memorable scenes, such as when a fragile country starlet spaces out on stage and begins rambling between numbers, or a disenchanted housewife waits at the back of a bar for a womanizing folk singer, or a poor deceived waitress is goaded into a striptease by a raucous crowd and still refuses to believe that she can't actually sing.   \\n\\nThis is rich film, a complex tapestry perfectly suited to a moment in time (the US Bicentennial) that seems as though it will reward additional viewings. I sometimes become fidgety during long movies but I was never bored with *Nashville*. It swept me along with its quirky and interesting characters to a climax that maybe I should have seen coming.  \\n\\n8/10\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df[\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "00d6d97b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "00d6d97b",
        "outputId": "476e87af-6c50-4983-def8-df429fe6c013"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"   It was only a few minutes into Robert Altman's homespun epic Nashville that I got the feeling I was watching a great movie. By the end it could not be denied. Now I am sure it helps that I am a musician, since this created an immediate connection to the subject matter. I spent a portion of the movie with my Telecaster in my lap trying to play along with the characters who all seem to be really playing and singing these songs. However I also am not a fan of country western, so that could have easily been a turn off. To begin describing the action in the film is daunting. I cannot even process a lot of what I saw. This movie is extremely dense, and the first 30 minutes or so are spent just trying to figure out who people are. Their relationships to one another - some of which are purely incidental - slowly become clear as things progress. It is an ensemble cast with no clear lead and lots of overlapping conversations. Some developments all tie together in the end. Some seem to be kind of loose ends. There is throughout, however, a very keen sense about people. These naturalistic performances are believable and so is the world they inhabit. It feels like a film that does not exaggerate - rather, it downplays some of the outrageousness which just makes it seem all the more outrageous. Consider for example Shelley Duvall's wig or Jeff Goldblum's entire character. I feel I should mention this. Jeff Goldblum is in this film. He never speaks, and he is awesome. Nashville is a musical. There is reportedly around an hour of music in its 150+ minute run time. I believe it. Sometimes these songs, most if not all of which are original, seem to speak pointedly to or about a character. Sometimes it is all about the shifts and glances in the audience. There are many memorable scenes, such as when a fragile country starlet spaces out on stage and begins rambling between numbers, or a disenchanted housewife waits at the back of a bar for a womanizing folk singer, or a poor deceived waitress is goaded into a striptease by a raucous crowd and still refuses to believe that she cannot actually sing. This is rich film, a complex tapestry perfectly suited to a moment in time (the US Bicentennial) that seems as though it will reward additional viewings. I sometimes become fidgety during long movies but I was never bored with Nashville. It swept me along with its quirky and interesting characters to a climax that maybe I should have seen coming. 8/10\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df[\"text_clean\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceaf58cd",
      "metadata": {
        "id": "ceaf58cd"
      },
      "source": [
        "### Prep for the Bert thingy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8007c98b",
      "metadata": {
        "id": "8007c98b"
      },
      "outputs": [],
      "source": [
        "# making a deep copy coz I think pandas works with shallow copies by default! \n",
        "train_df = df[[\"text_clean\", \"meta.majority_type\", \"meta.annotation-types\"]].copy() \n",
        "train_df.rename(columns={\"meta.majority_type\" : \"label\", \"meta.annotation-types\" : \"options\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "43028e02",
      "metadata": {
        "id": "43028e02"
      },
      "outputs": [],
      "source": [
        "# no need of index\n",
        "train_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "bd855695",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bd855695",
        "outputId": "2ed36889-a13f-4807-8806-06e654a8dd66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          text_clean         label  \\\n",
              "0     It was only a few minutes into Robert Altma...  announcement   \n",
              "1  I have wanted to watch this for a long time. I...   elaboration   \n",
              "2  You strike me as the type who would appreciate...   elaboration   \n",
              "3  Yeah, I have always heard that Altman was famo...   elaboration   \n",
              "4  Alright guys, little background about myself. ...  announcement   \n",
              "\n",
              "                                      options  \n",
              "0  [announcement, announcement, announcement]  \n",
              "1       [agreement, elaboration, elaboration]  \n",
              "2     [elaboration, elaboration, elaboration]  \n",
              "3       [agreement, elaboration, elaboration]  \n",
              "4  [announcement, announcement, announcement]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af382a15-065b-4c6c-9a39-f80534f56c8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_clean</th>\n",
              "      <th>label</th>\n",
              "      <th>options</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It was only a few minutes into Robert Altma...</td>\n",
              "      <td>announcement</td>\n",
              "      <td>[announcement, announcement, announcement]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have wanted to watch this for a long time. I...</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>[agreement, elaboration, elaboration]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You strike me as the type who would appreciate...</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>[elaboration, elaboration, elaboration]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yeah, I have always heard that Altman was famo...</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>[agreement, elaboration, elaboration]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alright guys, little background about myself. ...</td>\n",
              "      <td>announcement</td>\n",
              "      <td>[announcement, announcement, announcement]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af382a15-065b-4c6c-9a39-f80534f56c8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af382a15-065b-4c6c-9a39-f80534f56c8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af382a15-065b-4c6c-9a39-f80534f56c8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dealing with categorical data\n",
        "codes, labels = pd.factorize(train_df[\"label\"])"
      ],
      "metadata": {
        "id": "sDe2SYnYvlyo"
      },
      "id": "sDe2SYnYvlyo",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"label\"] = pd.Series(data=codes).copy()"
      ],
      "metadata": {
        "id": "i0dvWLiVyHm-"
      },
      "id": "i0dvWLiVyHm-",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "55N7QG9nymWt",
        "outputId": "66aaf92c-88fb-4458-840a-53d28bc89428"
      },
      "id": "55N7QG9nymWt",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          text_clean  label  \\\n",
              "0     It was only a few minutes into Robert Altma...      0   \n",
              "1  I have wanted to watch this for a long time. I...      1   \n",
              "2  You strike me as the type who would appreciate...      1   \n",
              "3  Yeah, I have always heard that Altman was famo...      1   \n",
              "4  Alright guys, little background about myself. ...      0   \n",
              "\n",
              "                                      options  \n",
              "0  [announcement, announcement, announcement]  \n",
              "1       [agreement, elaboration, elaboration]  \n",
              "2     [elaboration, elaboration, elaboration]  \n",
              "3       [agreement, elaboration, elaboration]  \n",
              "4  [announcement, announcement, announcement]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d08f362-2cd5-4c60-b176-f94ac68b1133\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_clean</th>\n",
              "      <th>label</th>\n",
              "      <th>options</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It was only a few minutes into Robert Altma...</td>\n",
              "      <td>0</td>\n",
              "      <td>[announcement, announcement, announcement]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have wanted to watch this for a long time. I...</td>\n",
              "      <td>1</td>\n",
              "      <td>[agreement, elaboration, elaboration]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You strike me as the type who would appreciate...</td>\n",
              "      <td>1</td>\n",
              "      <td>[elaboration, elaboration, elaboration]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yeah, I have always heard that Altman was famo...</td>\n",
              "      <td>1</td>\n",
              "      <td>[agreement, elaboration, elaboration]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alright guys, little background about myself. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[announcement, announcement, announcement]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d08f362-2cd5-4c60-b176-f94ac68b1133')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d08f362-2cd5-4c60-b176-f94ac68b1133 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d08f362-2cd5-4c60-b176-f94ac68b1133');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"label\"].value_counts()\n",
        "#-1 means that these are the labels that are missing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnPtKDHpv8Bx",
        "outputId": "1878e91f-cf9a-4aff-eec8-344d6a5d8a8f"
      },
      "id": "BnPtKDHpv8Bx",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 5    41162\n",
              " 1    19258\n",
              " 4    17594\n",
              "-1    12277\n",
              " 3     8710\n",
              " 6     5040\n",
              " 8     3422\n",
              " 2     2417\n",
              " 9     2049\n",
              " 0     2002\n",
              " 7     1896\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"num_tokens\"] = train_df[\"text_clean\"].apply(lambda sent : len(re.findall(r'\\w+', sent)))"
      ],
      "metadata": {
        "id": "RH1w7Qc2T6KE"
      },
      "id": "RH1w7Qc2T6KE",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removed all the token that exceeded the limit\n",
        "train_df = train_df[train_df[\"num_tokens\"]<510]"
      ],
      "metadata": {
        "id": "43Ir1qZWT6It"
      },
      "id": "43Ir1qZWT6It",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df[\"num_tokens\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwDd-BpFVRXr",
        "outputId": "017f74d1-b673-4e66-8199-f12c6bffcdbd"
      },
      "id": "nwDd-BpFVRXr",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115374"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"label\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5K7zLPjatu1",
        "outputId": "7e66a4d7-7e4d-48f2-88ab-2defdbee0ba9"
      },
      "id": "h5K7zLPjatu1",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 5    41009\n",
              " 1    19217\n",
              " 4    17479\n",
              "-1    12244\n",
              " 3     8707\n",
              " 6     5039\n",
              " 8     3414\n",
              " 2     2415\n",
              " 9     2040\n",
              " 0     1914\n",
              " 7     1896\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_missing = train_df.loc[train_df[\"label\"]<0]\n",
        "train_df_missing[\"label\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX-4cLPOa5DG",
        "outputId": "c5928b1a-f815-47aa-e802-acc2d54d205d"
      },
      "id": "hX-4cLPOa5DG",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    12244\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_labeled = train_df.loc[train_df[\"label\"]>=0]\n",
        "train_df_labeled[\"label\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h353pI-hbaVW",
        "outputId": "2c025c1a-1ed3-4475-8521-5c2215d62b52"
      },
      "id": "h353pI-hbaVW",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    41009\n",
              "1    19217\n",
              "4    17479\n",
              "3     8707\n",
              "6     5039\n",
              "8     3414\n",
              "2     2415\n",
              "9     2040\n",
              "0     1914\n",
              "7     1896\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "e201db4d",
      "metadata": {
        "id": "e201db4d"
      },
      "outputs": [],
      "source": [
        "# Checks if things are in order so far\n",
        "assert len(train_df_labeled.loc[train_df_labeled[\"label\"]<0]) == 0 \n",
        "assert len(train_df)-len(train_df_missing) == len(train_df_labeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "e02ee705",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e02ee705",
        "outputId": "5e160bec-9048-45d1-ed0b-9197e89ad8b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          text_clean  label  \\\n",
              "0     It was only a few minutes into Robert Altma...      0   \n",
              "1  I have wanted to watch this for a long time. I...      1   \n",
              "2  You strike me as the type who would appreciate...      1   \n",
              "3  Yeah, I have always heard that Altman was famo...      1   \n",
              "4  Alright guys, little background about myself. ...      0   \n",
              "\n",
              "                                      options  num_tokens  \n",
              "0  [announcement, announcement, announcement]         447  \n",
              "1       [agreement, elaboration, elaboration]          20  \n",
              "2     [elaboration, elaboration, elaboration]          74  \n",
              "3       [agreement, elaboration, elaboration]          21  \n",
              "4  [announcement, announcement, announcement]         102  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffc854b0-357a-429c-bc50-987422e09036\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_clean</th>\n",
              "      <th>label</th>\n",
              "      <th>options</th>\n",
              "      <th>num_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It was only a few minutes into Robert Altma...</td>\n",
              "      <td>0</td>\n",
              "      <td>[announcement, announcement, announcement]</td>\n",
              "      <td>447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have wanted to watch this for a long time. I...</td>\n",
              "      <td>1</td>\n",
              "      <td>[agreement, elaboration, elaboration]</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You strike me as the type who would appreciate...</td>\n",
              "      <td>1</td>\n",
              "      <td>[elaboration, elaboration, elaboration]</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yeah, I have always heard that Altman was famo...</td>\n",
              "      <td>1</td>\n",
              "      <td>[agreement, elaboration, elaboration]</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alright guys, little background about myself. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[announcement, announcement, announcement]</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffc854b0-357a-429c-bc50-987422e09036')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffc854b0-357a-429c-bc50-987422e09036 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffc854b0-357a-429c-bc50-987422e09036');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "train_df_labeled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "15a1f7cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15a1f7cc",
        "outputId": "7f7daad2-3b7c-4e55-df88-71b5e6b1e48c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    41009\n",
              "1    19217\n",
              "4    17479\n",
              "3     8707\n",
              "6     5039\n",
              "8     3414\n",
              "2     2415\n",
              "9     2040\n",
              "0     1914\n",
              "7     1896\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "train_df_labeled[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_labeled[\"num_tokens\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP47FrNMVnbm",
        "outputId": "19071c23-3834-4e8f-8dbf-5a5103a460b7"
      },
      "id": "xP47FrNMVnbm",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1      3110\n",
              "0      2863\n",
              "6      2663\n",
              "5      2578\n",
              "7      2486\n",
              "       ... \n",
              "478       1\n",
              "506       1\n",
              "473       1\n",
              "482       1\n",
              "504       1\n",
              "Name: num_tokens, Length: 502, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = train_df_labeled.iloc[3333]\n",
        "print(test[\"text_clean\"])\n",
        "print(test[\"num_tokens\"])\n",
        "print(test[\"label\"])\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-JFRmLtVnaU",
        "outputId": "dab5a24b-49da-462f-f58b-6f6b4b82eaf9"
      },
      "id": "c-JFRmLtVnaU",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stress\n",
            "1\n",
            "5\n",
            "Index(['announcement', 'elaboration', 'humor', 'appreciation', 'question',\n",
            "       'answer', 'agreement', 'negativereaction', 'disagreement', 'other'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"num_tokens\"].value_counts()"
      ],
      "metadata": {
        "id": "ROlVaf82Wnv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f73cd74-2a4a-4ec6-8208-a83686f0d946"
      },
      "id": "ROlVaf82Wnv8",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1      3503\n",
              "0      3170\n",
              "6      3118\n",
              "5      2961\n",
              "4      2873\n",
              "       ... \n",
              "430       1\n",
              "501       1\n",
              "473       1\n",
              "478       1\n",
              "504       1\n",
              "Name: num_tokens, Length: 502, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_missing[\"label\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO5iAN18rWkF",
        "outputId": "9cadf41a-d325-40e9-b94c-d071b02257b3"
      },
      "id": "IO5iAN18rWkF",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    12244\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT variants\n",
        "All the BERTs that have been trained on conversational data can be more benifical that just the vanilla bert trained on something like Wiki corpus.\n",
        "\n",
        "1. [ ] MPC-BERT : Trained on Multi-Party comm\n",
        "2. [ ] CS-BERT : Customer Service\n",
        "3. [ ] RobertA - [Link](https://huggingface.co/roberta-large-mnli)"
      ],
      "metadata": {
        "id": "QAThRqomEkk4"
      },
      "id": "QAThRqomEkk4"
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u_0k7623Ekfr"
      },
      "id": "u_0k7623Ekfr"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "8d5b01f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "447ba12f79ad4ac4a8286e3ad5f86737",
            "c7bc320fa9b244948a39ead1051b78af",
            "625b0ce8550146d896cacce6db6d4257",
            "d561eacde8ad403bbcf55fac41acdd91",
            "8c82fc492e3a4d4aa71cb41d099252ba",
            "263f3919ca2642e1a0585ffc267107f1",
            "14d4b4aaf5c245518fff505af3293adc",
            "e69a0caeba02469d8a737df0e4506933",
            "06b506cbdb8b4df081d102cf4ce6dedd",
            "3c827f10e89548298a16b749a2294a7d",
            "7a38dce51c4648f1a78d5ec5a3abcd00",
            "aee37dced625421f826d80297b809703",
            "3fcd347047ec4509ab186040bb4a513d",
            "ee521072c1244ff6a31e6a21db66a29a",
            "c465f8846eb84cbfb77ab0752f9470ec",
            "233118d102af41c5a436b70a1462d85d",
            "03cc62c746184fc5a4f97f11acfe2f3e",
            "1288a184550c469d9d3792162f6f2813",
            "b3a532586595483b9d4f7565ac03de3c",
            "f3d6ee5f04d9472cbe1f0968b66307f4",
            "54f482f9e0a14b60bb68a2aff6f6a49e",
            "199d6bf49de54c69923e908d1c7c8ead",
            "3273fb11bc0f44938bda6281dfc93fdd",
            "bef508b5a7db4cd7b057627c6d8b0ade",
            "fbef39ce845b4c39b16a97ee8a062782",
            "485639d6219d444cb0bf78e3e4950c5b",
            "da4880adbc2d450caa46d86c01f88fc1",
            "449a9559d1654feea6ce3d79e5ac1b55",
            "7e0b648b8e284f51b2c398598f7bac58",
            "24cd395911454f3991a4466eca367177",
            "4b401ad3043043daa435b1441224e317",
            "8eaea60a56764377966fe261aa4d432e",
            "b62affaaf61840bd8d90d376cb816e0b"
          ]
        },
        "id": "8d5b01f6",
        "outputId": "d522f84f-e55f-4d5c-8b33-adc6b7f079e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "447ba12f79ad4ac4a8286e3ad5f86737"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aee37dced625421f826d80297b809703"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3273fb11bc0f44938bda6281dfc93fdd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "#Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
        "#Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
        "#Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "735e5822",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "735e5822",
        "outputId": "c2e8fbd5-ec3e-4749-df69-79743c8c876a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  1996\n"
          ]
        }
      ],
      "source": [
        "max_len = 0\n",
        "all_sentences = train_df[\"text_clean\"]\n",
        "# For every sentence...\n",
        "for sent in all_sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the Hyper- for the sweep configurations we should follow : [Link](https://datascience.stackexchange.com/questions/64583/what-are-the-good-parameter-ranges-for-bert-hyperparameters-while-finetuning-it)\n",
        "\n",
        "The ones used in this block below are the ones that are suggested in the actual bert paper"
      ],
      "metadata": {
        "id": "NIXi_dMm-i7R"
      },
      "id": "NIXi_dMm-i7R"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "b57812e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b57812e6",
        "outputId": "afbbdc2e-1fd0-42b4-e938-94f9e5dde901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 8ln0jqog\n",
            "Sweep URL: https://wandb.ai/mistr/uncategorized/sweeps/8ln0jqog\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "sweep_config = {\n",
        "    'method': 'random', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "\n",
        "        'learning_rate': {\n",
        "            'values': [ 5e-5, 3e-5, 2e-5]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [4, 8]\n",
        "        },\n",
        "        'epochs':{\n",
        "            'values':[2, 3, 4]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "# sweep_defaults = {\n",
        "#     'learning_rate': 5e-5,\n",
        "#     'batch_size': 32,\n",
        "#     'epochs':2\n",
        "# }\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenization\n",
        "To follow a general convention that the sizes should be in powers of 2, well choose the closest number that is a power of 2, i.e, 64.\n",
        "\n",
        "Now, were ready to perform the real tokenization. But as were using transformers, we can use an inbuilt function tokenizer.encode_plus which automates all of the following tasks:\n",
        "\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "4. Pad or truncate all sentences to the same length.\n",
        "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n"
      ],
      "metadata": {
        "id": "eN4wOfjkb-aF"
      },
      "id": "eN4wOfjkb-aF"
    },
    {
      "cell_type": "code",
      "source": [
        "#Remember we are only working iwth the training set first as the label comparision for the missing labels 10% is still left - so for now this(train_df_labeled) would be ou entire dataset \n",
        "labeled_sentences = train_df_labeled[\"text_clean\"]\n",
        "given_labels = train_df_labeled[\"label\"]"
      ],
      "metadata": {
        "id": "oj-QoQD4WnxX"
      },
      "id": "oj-QoQD4WnxX",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_sentences.iloc[35]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j9n0Vw8ohVns",
        "outputId": "87832745-95fb-4462-919f-1de8eb27d417"
      },
      "id": "j9n0Vw8ohVns",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Whew! Cannot afford that one. I am lookin for the base model that sells on impactguns.com for like $540.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(labeled_sentences) == len(given_labels)"
      ],
      "metadata": {
        "id": "QYhgsBrghVmh"
      },
      "id": "QYhgsBrghVmh",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "2bb4f785",
      "metadata": {
        "id": "2bb4f785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "236c297a-94ee-426a-861a-0d8823fe5fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in labeled_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(given_labels, dtype=torch.int)\n",
        "\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', labeled_sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2JqznZNoSOS",
        "outputId": "83e3bcea-c6af-4888-ba99-582bdfc8ea2d"
      },
      "id": "o2JqznZNoSOS",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:     It was only a few minutes into Robert Altman's homespun epic Nashville that I got the feeling I was watching a great movie. By the end it could not be denied. Now I am sure it helps that I am a musician, since this created an immediate connection to the subject matter. I spent a portion of the movie with my Telecaster in my lap trying to play along with the characters who all seem to be really playing and singing these songs. However I also am not a fan of country western, so that could have easily been a turn off. To begin describing the action in the film is daunting. I cannot even process a lot of what I saw. This movie is extremely dense, and the first 30 minutes or so are spent just trying to figure out who people are. Their relationships to one another - some of which are purely incidental - slowly become clear as things progress. It is an ensemble cast with no clear lead and lots of overlapping conversations. Some developments all tie together in the end. Some seem to be kind of loose ends. There is throughout, however, a very keen sense about people. These naturalistic performances are believable and so is the world they inhabit. It feels like a film that does not exaggerate - rather, it downplays some of the outrageousness which just makes it seem all the more outrageous. Consider for example Shelley Duvall's wig or Jeff Goldblum's entire character. I feel I should mention this. Jeff Goldblum is in this film. He never speaks, and he is awesome. Nashville is a musical. There is reportedly around an hour of music in its 150+ minute run time. I believe it. Sometimes these songs, most if not all of which are original, seem to speak pointedly to or about a character. Sometimes it is all about the shifts and glances in the audience. There are many memorable scenes, such as when a fragile country starlet spaces out on stage and begins rambling between numbers, or a disenchanted housewife waits at the back of a bar for a womanizing folk singer, or a poor deceived waitress is goaded into a striptease by a raucous crowd and still refuses to believe that she cannot actually sing. This is rich film, a complex tapestry perfectly suited to a moment in time (the US Bicentennial) that seems as though it will reward additional viewings. I sometimes become fidgety during long movies but I was never bored with Nashville. It swept me along with its quirky and interesting characters to a climax that maybe I should have seen coming. 8/10\n",
            "Token IDs: tensor([  101,  2009,  2001,  2069,  1037,  2261,  2781,  2046,  2728, 12456,\n",
            "         2386,  1005,  1055,  5014, 14289,  2078,  8680,  8423,  2008,  1045,\n",
            "         2288,  1996,  3110,  1045,  2001,  3666,  1037,  2307,  3185,  1012,\n",
            "         2011,  1996,  2203,  2009,  2071,  2025,  2022,  6380,  1012,  2085,\n",
            "         1045,  2572,  2469,  2009,  7126,  2008,  1045,  2572,  1037,  5455,\n",
            "         1010,  2144,  2023,  2580,  2019,  6234,  4434,  2000,  1996,  3395,\n",
            "         3043,  1012,  1045,  2985,  1037,  4664,  1997,  1996,  3185,  2007,\n",
            "         2026, 28803,  2121,  1999,  2026,  5001,  2667,  2000,  2377,  2247,\n",
            "         2007,  1996,  3494,  2040,  2035,  4025,  2000,  2022,  2428,  2652,\n",
            "         1998,  4823,  2122,  2774,  1012,  2174,  1045,  2036,  2572,  2025,\n",
            "         1037,  5470,  1997,  2406,  2530,  1010,  2061,  2008,  2071,  2031,\n",
            "         4089,  2042,  1037,  2735,  2125,  1012,  2000,  4088,  7851,  1996,\n",
            "         2895,  1999,  1996,  2143,  2003,  4830, 16671,  2075,  1012,  1045,\n",
            "         3685,  2130,  2832,  1037,  2843,  1997,  2054,  1045,  2387,  1012,\n",
            "         2023,  3185,  2003,  5186,  9742,  1010,  1998,  1996,  2034,  2382,\n",
            "         2781,  2030,  2061,  2024,  2985,  2074,  2667,  2000,  3275,  2041,\n",
            "         2040,  2111,  2024,  1012,  2037,  6550,  2000,  2028,  2178,  1011,\n",
            "         2070,  1997,  2029,  2024, 11850,  5043,  2389,  1011,  3254,  2468,\n",
            "         3154,  2004,  2477,  5082,  1012,  2009,  2003,  2019,  7241,  3459,\n",
            "         2007,  2053,  3154,  2599,  1998,  7167,  1997, 20567, 11450,  1012,\n",
            "         2070,  8973,  2035,  5495,  2362,  1999,  1996,  2203,  1012,  2070,\n",
            "         4025,  2000,  2022,  2785,  1997,  6065,  4515,  1012,  2045,  2003,\n",
            "         2802,  1010,  2174,  1010,  1037,  2200, 10326,  3168,  2055,  2111,\n",
            "         1012,  2122, 19176,  2594,  4616,  2024, 19337,  2666, 12423,  1998,\n",
            "         2061,  2003,  1996,  2088,  2027, 21490,  1012,  2009,  5683,  2066,\n",
            "         1037,  2143,  2008,  2515,  2025,  4654, 27609,  3686,  1011,  2738,\n",
            "         1010,  2009,  2091, 13068,  2015,  2070,  1997,  1996, 25506,  2791,\n",
            "         2029,  2074,  3084,  2009,  4025,  2035,  1996,  2062, 25506,  1012,\n",
            "         5136,  2005,  2742, 15828, 23929,  2140,  1005,  1055, 24405,  2030,\n",
            "         5076,  2751, 16558,  2819,  1005,  1055,  2972,  2839,  1012,  1045,\n",
            "         2514,  1045,  2323,  5254,  2023,  1012,  5076,  2751, 16558,  2819,\n",
            "         2003,  1999,  2023,  2143,  1012,  2002,  2196,  8847,  1010,  1998,\n",
            "         2002,  2003, 12476,  1012,  8423,  2003,  1037,  3315,  1012,  2045,\n",
            "         2003,  7283,  2105,  2019,  3178,  1997,  2189,  1999,  2049,  5018,\n",
            "         1009,  3371,  2448,  2051,  1012,  1045,  2903,  2009,  1012,  2823,\n",
            "         2122,  2774,  1010,  2087,  2065,  2025,  2035,  1997,  2029,  2024,\n",
            "         2434,  1010,  4025,  2000,  3713, 28713,  2000,  2030,  2055,  1037,\n",
            "         2839,  1012,  2823,  2009,  2003,  2035,  2055,  1996, 12363,  1998,\n",
            "        13021,  1999,  1996,  4378,  1012,  2045,  2024,  2116, 13432,  5019,\n",
            "         1010,  2107,  2004,  2043,  1037, 13072,  2406,  2732,  7485,  7258,\n",
            "         2041,  2006,  2754,  1998,  4269,  8223,  9709,  2090,  3616,  1010,\n",
            "         2030,  1037,  4487,  5054, 14856,  3064,  2160, 19993, 18074,  2012,\n",
            "         1996,  2067,  1997,  1037,  3347,  2005,  1037,  2450,  6026,  5154,\n",
            "         3220,  1010,  2030,  1037,  3532, 11703,  7416,  7178, 13877,  2003,\n",
            "        15244,  5732,  2046,  1037,  6167, 27058,  3366,  2011,  1037, 10958,\n",
            "        14194,  3560,  4306,  1998,  2145, 10220,  2000,  2903,  2008,  2016,\n",
            "         3685,  2941,  6170,  1012,  2023,  2003,  4138,  2143,  1010,  1037,\n",
            "         3375, 25213,  6669, 10897,  2000,  1037,  2617,  1999,  2051,  1006,\n",
            "         1996,  2149, 12170, 13013, 22929,  1007,  2008,  3849,  2004,  2295,\n",
            "         2009,  2097, 10377,  3176, 10523,  2015,  1012,  1045,  2823,  2468,\n",
            "        10882, 24291,  2100,  2076,  2146,  5691,  2021,  1045,  2001,  2196,\n",
            "        11471,   102])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train - Test Split\n",
        "\n"
      ],
      "metadata": {
        "id": "tgrNAoiXiSd2"
      },
      "id": "tgrNAoiXiSd2"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "3822c397",
      "metadata": {
        "id": "3822c397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0efab4-2e08-40a1-e13c-5a56277049d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87660 training samples present\n",
            "15470 validation samples present\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"{train_size} training samples present\")\n",
        "print(f\"{val_size} validation samples present\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "70306025",
      "metadata": {
        "id": "70306025"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "import wandb\n",
        "# WANDB PARAMETER\n",
        "def ret_dataloader():\n",
        "    batch_size = wandb.config.batch_size\n",
        "    print('batch_size = ', batch_size)\n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    return train_dataloader,validation_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "bba03c38",
      "metadata": {
        "id": "bba03c38"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "def ret_model():\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\", \n",
        "        num_labels = 2, \n",
        "        output_attentions = False, # Whether the model returns attentions weights.\n",
        "        output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "d0d970d3",
      "metadata": {
        "id": "d0d970d3"
      },
      "outputs": [],
      "source": [
        "def ret_optim(model):\n",
        "    print('Learning_rate = ',wandb.config.learning_rate )\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                      lr = wandb.config.learning_rate, \n",
        "                      eps = 1e-8 \n",
        "                    )\n",
        "    return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def ret_scheduler(train_dataloader,optimizer):\n",
        "    epochs = wandb.config.epochs\n",
        "    print('epochs =>', epochs)\n",
        "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "    # (Note that this is not the same as the number of training samples).\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Create the learning rate scheduler.\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                num_training_steps = total_steps)\n",
        "    return scheduler"
      ],
      "metadata": {
        "id": "aFYJBnpvubP6"
      },
      "id": "aFYJBnpvubP6",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "_Cm-8FJYroaI"
      },
      "id": "_Cm-8FJYroaI",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a ton to explore here with wandb man - [video](https://www.youtube.com/watch?v=9zrmUIlScdY) \n",
        "\n",
        "1. [ ] Use various models in the yaml file?\n",
        "2. [ ] Use different host machines - We could use lab computers to train/tune the hyperparameters"
      ],
      "metadata": {
        "id": "fKvIIibvqrE2"
      },
      "id": "fKvIIibvqrE2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Function"
      ],
      "metadata": {
        "id": "qWKeEVmasQbt"
      },
      "id": "qWKeEVmasQbt"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def train():\n",
        "  wandb.init()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(device)\n",
        "  \n",
        "  model = ret_model()\n",
        "  model.to(device)\n",
        "  train_dataloader, validation_dataloader = ret_dataloader()\n",
        "  \n",
        "  optimizer = ret_optim(model)\n",
        "  \n",
        "  scheduler = ret_scheduler(train_dataloader, optimizer)\n",
        "  \n",
        "  training_stats = []\n",
        "  total_t0 = time.time()\n",
        "  epochs = wandb.config.epochs\n",
        "\n",
        "  for epoch_i in range(0,epochs):\n",
        "    \n",
        "    #Training\n",
        "    print(f'========== EPOCH {epoch_i+1} / {epochs} =========')\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      if step % 40 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time()-t0)\n",
        "\n",
        "        print(f\" Batch {step} of {len(train_dataloader)}.     Elapsed : {elapsed}\")\n",
        "      \n",
        "      # UNpackign the batch data and sending to gpu\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "      loss, logits = model(b_input_ids, \n",
        "                            token_type_ids = None,\n",
        "                            attention_mask = b_input_mask,\n",
        "                            labels = b_labels)\n",
        "      \n",
        "      #Log the train loss in WandB\n",
        "      wandb.log({'train_batch_loss': loss.item()})\n",
        "      total_train_loss += loss.item()\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "    \n",
        "\n",
        "    avg_train_loss = total_train_loss/len(train_dataloader)\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    #Log the avg train loss\n",
        "    wandb.log({'avg_trin_loss' : avg_train_loss})\n",
        "    print(\"\")\n",
        "    \n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    \n",
        "    # Validation\n",
        "    print(\"Running Validation ...\")\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    #Evaluatea dat for each epoch \n",
        "    for batch in validation_dataloader:\n",
        "      # UNpackign the batch data and sending to gpu\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "\n",
        "      # No BP - Validation\n",
        "      with torch.no_grad:\n",
        "        (loss, logits) = model(b_input_ids, \n",
        "                            token_type_ids = None,\n",
        "                            attention_mask = b_input_mask,\n",
        "                            labels = b_labels)\n",
        "        \n",
        "      total_eval_loss += loss.item()\n",
        "\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "      total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy/len(validation_dataloader)\n",
        "    print(\"     Accuracy : {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    #Log Avg val accuracy \n",
        "    wandb.log({\"val_accuracy\" : avg_val_accuracy, 'avg_val_loss' : avg_val_loss})\n",
        "    print(\"     Validation Loss : {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0))) \n",
        "\n"
      ],
      "metadata": {
        "id": "0U2zLgSLtNVF"
      },
      "id": "0U2zLgSLtNVF",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id,function=train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "Ezp9Fd9_2iKn",
        "outputId": "778be780-8e1d-4b51-ab48-6fcd05e002de"
      },
      "id": "Ezp9Fd9_2iKn",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 92jamtjs with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem at: <ipython-input-85-f3eec1218d0e> 5 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\", line 996, in init\n",
            "    run = wi.init()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\", line 671, in init\n",
            "    _ = backend.interface.communicate_run_start(run_obj)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\", line 221, in communicate_run_start\n",
            "    result = self._communicate_run_start(run_start)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 439, in _communicate_run_start\n",
            "    result = self._communicate(rec)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 225, in _communicate\n",
            "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/router.py\", line 37, in get\n",
            "    is_set = self._object_ready.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 552, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "Exception\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "#     # This training code is based on the `run_glue.py` script here:\n",
        "#     # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "#     # Set the seed value all over the place to make this reproducible.\n",
        "# def train():\n",
        "#     wandb.init(config=sweep_defaults)\n",
        "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#     print(device)\n",
        "#     model = ret_model()\n",
        "#     model.to(device)\n",
        "#     #wandb.init(config=sweep_defaults)\n",
        "#     train_dataloader,validation_dataloader = ret_dataloader()\n",
        "#     optimizer = ret_optim(model)\n",
        "#     scheduler = ret_scheduler(train_dataloader,optimizer)\n",
        "\n",
        "#     #print(\"config \",wandb.config.learning_rate, \"\\n\",wandb.config)\n",
        "#     seed_val = 42\n",
        "   \n",
        "#     random.seed(seed_val)\n",
        "#     np.random.seed(seed_val)\n",
        "#     torch.manual_seed(seed_val)\n",
        "#     #torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "#     # We'll store a number of quantities such as training and validation loss, \n",
        "#     # validation accuracy, and timings.\n",
        "#     training_stats = []\n",
        "\n",
        "#     # Measure the total training time for the whole run.\n",
        "#     total_t0 = time.time()\n",
        "#     epochs = wandb.config.epochs\n",
        "#     # For each epoch...\n",
        "#     for epoch_i in range(0, epochs):\n",
        "        \n",
        "#         # ========================================\n",
        "#         #               Training\n",
        "#         # ========================================\n",
        "        \n",
        "#         # Perform one full pass over the training set.\n",
        "\n",
        "#         print(\"\")\n",
        "#         print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "#         print('Training...')\n",
        "\n",
        "#         # Measure how long the training epoch takes.\n",
        "#         t0 = time.time()\n",
        "\n",
        "#         # Reset the total loss for this epoch.\n",
        "#         total_train_loss = 0\n",
        "\n",
        "#         # Put the model into training mode. Don't be mislead--the call to \n",
        "#         # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "#         # `dropout` and `batchnorm` layers behave differently during training\n",
        "#         # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "#         model.train()\n",
        "\n",
        "#         # For each batch of training data...\n",
        "#         for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "#             # Progress update every 40 batches.\n",
        "#             if step % 40 == 0 and not step == 0:\n",
        "#                 # Calculate elapsed time in minutes.\n",
        "#                 elapsed = format_time(time.time() - t0)\n",
        "                \n",
        "#                 # Report progress.\n",
        "#                 print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "#             # Unpack this training batch from our dataloader. \n",
        "#             #\n",
        "#             # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "#             # `to` method.\n",
        "#             #\n",
        "#             # `batch` contains three pytorch tensors:\n",
        "#             #   [0]: input ids \n",
        "#             #   [1]: attention masks\n",
        "#             #   [2]: labels \n",
        "#             b_input_ids = batch[0].to(device)\n",
        "#             b_input_mask = batch[1].to(device)\n",
        "#             b_labels = batch[2].to(device)\n",
        "\n",
        "#             # Always clear any previously calculated gradients before performing a\n",
        "#             # backward pass. PyTorch doesn't do this automatically because \n",
        "#             # accumulating the gradients is \"convenient while training RNNs\". \n",
        "#             # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "#             model.zero_grad()        \n",
        "\n",
        "#             # Perform a forward pass (evaluate the model on this training batch).\n",
        "#             # The documentation for this `model` function is here: \n",
        "#             # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "#             # It returns different numbers of parameters depending on what arguments\n",
        "#             # arge given and what flags are set. For our useage here, it returns\n",
        "#             # the loss (because we provided labels) and the \"logits\"--the model\n",
        "#             # outputs prior to activation.\n",
        "#             outputs = model(b_input_ids, \n",
        "#                                 token_type_ids=None, \n",
        "#                                 attention_mask=b_input_mask, \n",
        "#                                 labels=b_labels)\n",
        "#             loss, logits = outputs['loss'], outputs['logits']\n",
        "#             wandb.log({'train_batch_loss':loss.item()})\n",
        "#             # Accumulate the training loss over all of the batches so that we can\n",
        "#             # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "#             # single value; the `.item()` function just returns the Python value \n",
        "#             # from the tensor.\n",
        "#             total_train_loss += loss.item()\n",
        "\n",
        "#             # Perform a backward pass to calculate the gradients.\n",
        "#             loss.backward()\n",
        "\n",
        "#             # Clip the norm of the gradients to 1.0.\n",
        "#             # This is to help prevent the \"exploding gradients\" problem.\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "#             # Update parameters and take a step using the computed gradient.\n",
        "#             # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "#             # modified based on their gradients, the learning rate, etc.\n",
        "#             optimizer.step()\n",
        "\n",
        "#             # Update the learning rate.\n",
        "#             scheduler.step()\n",
        "\n",
        "#         # Calculate the average loss over all of the batches.\n",
        "#         avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        \n",
        "#         # Measure how long this epoch took.\n",
        "#         training_time = format_time(time.time() - t0)\n",
        "\n",
        "#         wandb.log({'avg_train_loss':avg_train_loss})\n",
        "\n",
        "#         print(\"\")\n",
        "#         print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "#         print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "            \n",
        "#         # ========================================\n",
        "#         #               Validation\n",
        "#         # ========================================\n",
        "#         # After the completion of each training epoch, measure our performance on\n",
        "#         # our validation set.\n",
        "\n",
        "#         print(\"\")\n",
        "#         print(\"Running Validation...\")\n",
        "\n",
        "#         t0 = time.time()\n",
        "\n",
        "#         # Put the model in evaluation mode--the dropout layers behave differently\n",
        "#         # during evaluation.\n",
        "#         model.eval()\n",
        "\n",
        "#         # Tracking variables \n",
        "#         total_eval_accuracy = 0\n",
        "#         total_eval_loss = 0\n",
        "#         nb_eval_steps = 0\n",
        "\n",
        "#         # Evaluate data for one epoch\n",
        "#         for batch in validation_dataloader:\n",
        "            \n",
        "#             # Unpack this training batch from our dataloader. \n",
        "#             #\n",
        "#             # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "#             # the `to` method.\n",
        "#             #\n",
        "#             # `batch` contains three pytorch tensors:\n",
        "#             #   [0]: input ids \n",
        "#             #   [1]: attention masks\n",
        "#             #   [2]: labels \n",
        "#             b_input_ids = batch[0].cuda()\n",
        "#             b_input_mask = batch[1].to(device)\n",
        "#             b_labels = batch[2].to(device)\n",
        "            \n",
        "#             # Tell pytorch not to bother with constructing the compute graph during\n",
        "#             # the forward pass, since this is only needed for backprop (training).\n",
        "#             with torch.no_grad():        \n",
        "\n",
        "#                 # Forward pass, calculate logit predictions.\n",
        "#                 # token_type_ids is the same as the \"segment ids\", which \n",
        "#                 # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "#                 # The documentation for this `model` function is here: \n",
        "#                 # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "#                 # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "#                 # values prior to applying an activation function like the softmax.\n",
        "#                 outputs = model(b_input_ids, \n",
        "#                                       token_type_ids=None, \n",
        "#                                       attention_mask=b_input_mask,\n",
        "#                                       labels=b_labels)\n",
        "#                 loss, logits = outputs['loss'], outputs['logits']\n",
        "                \n",
        "#             # Accumulate the validation loss.\n",
        "#             total_eval_loss += loss.item()\n",
        "\n",
        "#             # Move logits and labels to CPU\n",
        "#             logits = logits.detach().cpu().numpy()\n",
        "#             label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "#             # Calculate the accuracy for this batch of test sentences, and\n",
        "#             # accumulate it over all batches.\n",
        "#             total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "\n",
        "#         # Report the final accuracy for this validation run.\n",
        "#         avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "#         print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "#         # Calculate the average loss over all of the batches.\n",
        "#         avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "        \n",
        "#         # Measure how long the validation run took.\n",
        "#         validation_time = format_time(time.time() - t0)\n",
        "#         wandb.log({'val_accuracy':avg_val_accuracy,'avg_val_loss':avg_val_loss})\n",
        "#         print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "#         print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "#         # Record all statistics from this epoch.\n",
        "#         training_stats.append(\n",
        "#             {\n",
        "#                 'epoch': epoch_i + 1,\n",
        "#                 'Training Loss': avg_train_loss,\n",
        "#                 'Valid. Loss': avg_val_loss,\n",
        "#                 'Valid. Accur.': avg_val_accuracy,\n",
        "#                 'Training Time': training_time,\n",
        "#                 'Validation Time': validation_time\n",
        "#             }\n",
        "#         )\n",
        "\n",
        "#     print(\"\")\n",
        "#     print(\"Training complete!\")\n",
        "\n",
        "#     print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "id": "nyTbLE8jno88"
      },
      "id": "nyTbLE8jno88",
      "execution_count": 82,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "1.0-ish-Node-Classifier-Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eefd4ed0",
        "9ca0c211",
        "78050e6c",
        "13e0c1e1",
        "1cc6e165",
        "ceaf58cd"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "447ba12f79ad4ac4a8286e3ad5f86737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7bc320fa9b244948a39ead1051b78af",
              "IPY_MODEL_625b0ce8550146d896cacce6db6d4257",
              "IPY_MODEL_d561eacde8ad403bbcf55fac41acdd91"
            ],
            "layout": "IPY_MODEL_8c82fc492e3a4d4aa71cb41d099252ba"
          }
        },
        "c7bc320fa9b244948a39ead1051b78af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_263f3919ca2642e1a0585ffc267107f1",
            "placeholder": "",
            "style": "IPY_MODEL_14d4b4aaf5c245518fff505af3293adc",
            "value": "Downloading: 100%"
          }
        },
        "625b0ce8550146d896cacce6db6d4257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e69a0caeba02469d8a737df0e4506933",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06b506cbdb8b4df081d102cf4ce6dedd",
            "value": 231508
          }
        },
        "d561eacde8ad403bbcf55fac41acdd91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c827f10e89548298a16b749a2294a7d",
            "placeholder": "",
            "style": "IPY_MODEL_7a38dce51c4648f1a78d5ec5a3abcd00",
            "value": " 226k/226k [00:00&lt;00:00, 874kB/s]"
          }
        },
        "8c82fc492e3a4d4aa71cb41d099252ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "263f3919ca2642e1a0585ffc267107f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d4b4aaf5c245518fff505af3293adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e69a0caeba02469d8a737df0e4506933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b506cbdb8b4df081d102cf4ce6dedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c827f10e89548298a16b749a2294a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a38dce51c4648f1a78d5ec5a3abcd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aee37dced625421f826d80297b809703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fcd347047ec4509ab186040bb4a513d",
              "IPY_MODEL_ee521072c1244ff6a31e6a21db66a29a",
              "IPY_MODEL_c465f8846eb84cbfb77ab0752f9470ec"
            ],
            "layout": "IPY_MODEL_233118d102af41c5a436b70a1462d85d"
          }
        },
        "3fcd347047ec4509ab186040bb4a513d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03cc62c746184fc5a4f97f11acfe2f3e",
            "placeholder": "",
            "style": "IPY_MODEL_1288a184550c469d9d3792162f6f2813",
            "value": "Downloading: 100%"
          }
        },
        "ee521072c1244ff6a31e6a21db66a29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a532586595483b9d4f7565ac03de3c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3d6ee5f04d9472cbe1f0968b66307f4",
            "value": 28
          }
        },
        "c465f8846eb84cbfb77ab0752f9470ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f482f9e0a14b60bb68a2aff6f6a49e",
            "placeholder": "",
            "style": "IPY_MODEL_199d6bf49de54c69923e908d1c7c8ead",
            "value": " 28.0/28.0 [00:00&lt;00:00, 737B/s]"
          }
        },
        "233118d102af41c5a436b70a1462d85d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03cc62c746184fc5a4f97f11acfe2f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1288a184550c469d9d3792162f6f2813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3a532586595483b9d4f7565ac03de3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d6ee5f04d9472cbe1f0968b66307f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54f482f9e0a14b60bb68a2aff6f6a49e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199d6bf49de54c69923e908d1c7c8ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3273fb11bc0f44938bda6281dfc93fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bef508b5a7db4cd7b057627c6d8b0ade",
              "IPY_MODEL_fbef39ce845b4c39b16a97ee8a062782",
              "IPY_MODEL_485639d6219d444cb0bf78e3e4950c5b"
            ],
            "layout": "IPY_MODEL_da4880adbc2d450caa46d86c01f88fc1"
          }
        },
        "bef508b5a7db4cd7b057627c6d8b0ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_449a9559d1654feea6ce3d79e5ac1b55",
            "placeholder": "",
            "style": "IPY_MODEL_7e0b648b8e284f51b2c398598f7bac58",
            "value": "Downloading: 100%"
          }
        },
        "fbef39ce845b4c39b16a97ee8a062782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24cd395911454f3991a4466eca367177",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b401ad3043043daa435b1441224e317",
            "value": 570
          }
        },
        "485639d6219d444cb0bf78e3e4950c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eaea60a56764377966fe261aa4d432e",
            "placeholder": "",
            "style": "IPY_MODEL_b62affaaf61840bd8d90d376cb816e0b",
            "value": " 570/570 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "da4880adbc2d450caa46d86c01f88fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449a9559d1654feea6ce3d79e5ac1b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e0b648b8e284f51b2c398598f7bac58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24cd395911454f3991a4466eca367177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b401ad3043043daa435b1441224e317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eaea60a56764377966fe261aa4d432e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b62affaaf61840bd8d90d376cb816e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}